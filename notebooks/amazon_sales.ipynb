{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from src.data.dataset_reader import DatasetReader\n",
    "from pathlib import Path\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "data_folder = Path(\"../data/raw\").resolve()\n",
    "\n",
    "amazon = DatasetReader(data_folder).get_data_csv('Amazon Sale Report.csv')\n",
    "#int_sales = DatasetReader(data_folder).get_data_csv('International sale Report.csv')\n",
    "#p_l = DatasetReader(data_folder).get_data_csv('P LMarch2021.csv')\n",
    "#may_2022 = DatasetReader(data_folder).get_data_csv('May-2022.csv')\n",
    "#sale_report = DatasetReader(data_folder).get_data_csv('Sale Report.csv')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This dataset provides an in-depth look at the profitability of e-commerce sales. It contains data on a variety of sales channels, including Shiprocket and INCREFF, as well as financial information on related expenses and profits. The columns contain data such as SKU codes, design numbers, stock levels, product categories, sizes and colors. In addition to this we have included the MRPs across multiple stores like Ajio MRP , Amazon MRP , Amazon FBA MRP , Flipkart MRP , Limeroad MRP Myntra MRP and PaytmMRP along with other key parameters like amount paid by customer for the purchase , rate per piece for every individual transaction Also we have added transactional parameters like Date of sale months category fulfilledby B2b Status Qty Currency Gross amt . This is a must-have dataset for anyone trying to uncover the profitability of e-commerce sales in today's marketplace.\n",
    "This dataset provides a comprehensive overview of e-commerce sales data from different channels covering a variety of products. Using this dataset, retailers and digital marketers can measure the performance of their campaigns more accurately and efficiently.\n",
    "\n",
    "The following steps help users make the most out of this dataset:\n",
    "\n",
    "Analyze the general sales trends by examining info such as month, category, currency, stock level, and customer for each sale. This will give you an idea about how your e-commerce business is performing in each channel.\n",
    "\n",
    "Review the Shiprocket and INCREF data to compare and analyze profitability via different fulfilment methods. This comparison would enable you to make better decisions towards maximizing profit while minimizing costs associated with each method’s referral fees and fulfillment rates.\n",
    "\n",
    "Compare prices between various channels such as Amazon FBA MRP, Myntra MRP, Ajio MRP etc using  the corresponding columns for each store (Amazon MRP etc). You can judge which stores are offering more profitable margins without compromising on quality by analyzing these pricing points in combination with other information related to product sales (TP1/TP2 - cost per piece).\n",
    "\n",
    "Look at customer specific data such as TP 1/TP 2 combination wise Gross Amount or Rate info in terms price per piece or total gross amount generated by any SKU dispersed over multiple customers with relevant dates associated to track individual item performance relative to others within its category over time periods shortlisted/filtered appropriately.. Have an eye on items commonly utilized against offers or promotional discounts offered hence crafting strategies towards inventory optimization leading up-selling operations.?\n",
    "\n",
    "Finally Use Overall ‘Stock’ details along all the P & L Data including Yearly Expenses_IIGF information record for takeaways which might be aimed towards essential cost cutting measures like switching amongst delivery options carefully chosen out of Shiprocket & INCREFF leadings away from manual inspections catering savings under support personnel outsourcing structures.?  \n",
    "\n",
    "By employing a comprehensive understanding on how our internal subsidiaries perform globally unless attached respective audits may provide us remarkably lower operational costs servicing confidence; costing far lesser than being incurred taking into account entire pallet shipments tracking sheets representing current level supply chains efficiencies achieved internally., then one may finally scale profits exponentially increases cut down unseen losses followed up introducing newer marketing campaigns necessarily tailored according playing around multiple goods based spectrums due powerful backing suitable transportation boundaries set carefully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', None)\n",
    "amazon.head(3)\n",
    "#amazon.query('SKU == \"SET389-KR-NP-S\"').head(1)\n",
    "                                             \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new feature called sales that is the  the count of \"Amount\" grouped by \"SKU\" in the amazon dataset\n",
    "#amazon['sales'] = amazon.groupby('SKU')['Amount'].transform('count')\n",
    "#amazon.drop(columns=[ 'Order ID', 'ASIN', 'Unnamed: 22', 'index'], inplace=True\n",
    "amazon['Date'] = pd.to_datetime(amazon['Date'])\n",
    "amazon['ship-postal-code'] = amazon['ship-postal-code'].astype('object')\n",
    "amazon_beta =  amazon[['Order ID','Date', 'SKU', 'Qty', 'Amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_beta =  amazon[['Order ID','Date', 'SKU', 'Qty', 'Amount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.eda import Eda\n",
    "eda = Eda(    \n",
    ")\n",
    "\n",
    "eda.missing_values_table(amazon_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_beta.rename(columns={'Amount': 'price'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_beta.head()\n",
    "# Create a column called \"sales\" that is the count of the \"Order ID\" grouped by \"SKU\" and \"Date\" in the amazon_beta dataset\n",
    "amazon_beta['sales'] = amazon_beta.groupby(['SKU', 'Date'])['Order ID'].transform('count')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_beta.query('SKU == \"SET389-KR-NP-S\"').sort_values(by=['Date'], ascending=True).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show duplicates in amazon_beta \n",
    "#amazon_beta[amazon_beta.duplicated(keep=False)].sort_values(by='SKU', ascending=True).head(10)\n",
    "# drop duplicates in amazon_beta\n",
    "#amazon_beta.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eda.missing_values_table(amazon_beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_beta.sort_values(by=['SKU', 'Date'], ascending=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.feature_engineering import FeatureEngineeringProcess\n",
    "fep = FeatureEngineeringProcess()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_beta_fe1 = fep.price_sales_correlation_features_updated(amazon_beta, 15, [1, 2], [1,2],)\n",
    "amazon_beta_fe1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print this instruction: amazon_beta_fe1.query('SKU == \"SET389-KR-NP-S\"') without index\n",
    "amazon_beta_fe1.query('SKU == \"SET389-KR-NP-S\"').head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_beta_fe2 = fep.normalize_features(amazon_beta_fe1, 8, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_beta_fe2.query('SKU == \"SET389-KR-NP-S\"').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_beta_fe3 = fep.filter_stability_periods(amazon_beta_fe2, 7, 0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print without index amazon_beta_fe3.query('SKU == \"SET389-KR-NP-S\"') without index column\n",
    "\n",
    "\n",
    "amazon_beta_fe3[['Order ID', 'Date', 'SKU', 'price', 'sales','avg_price_last_7_days', 'price_variation']].query('SKU == \"SET389-KR-NP-S\"')\n",
    "\n",
    "\n",
    "# NOTE: Still seeing repeated values in the \"price\" column. Either low the threshold or increase removal_percentage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eda.missing_values_table(amazon_beta_fe3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_beta_fe3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows where price is null\n",
    "amazon_beta_train = amazon_beta_fe3.dropna(subset=['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_beta_train.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_beta_train1= fep.datetime_transform(amazon_beta_train, 'Date',['day_of_the_year', 'month', 'day_of_the_week', 'season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Order Id, price_variation, insufficient_data\n",
    "amazon_beta_train1.drop(columns=['Order ID', 'price_variation', 'insufficient_data'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_beta_train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.data.data_splitter import DataSplitter\n",
    "\n",
    "splitter = DataSplitter(amazon_beta_train1, train_months=3, test_weeks=2)\n",
    "train, test = splitter.split_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Date column\n",
    "train.drop(columns=['Date'], inplace=True)\n",
    "test.drop(columns=['Date'], inplace=True)\n",
    "# one hot encode Date_season\n",
    "train = pd.get_dummies(train, columns=['Date_season'])\n",
    "test = pd.get_dummies(test, columns=['Date_season'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "\n",
    "\n",
    "# Define and train XGBoost model\n",
    "xgboost_model = XGBRegressor(n_estimators=500, learning_rate=0.1, max_depth=6)\n",
    "xgboost_model.fit(train.drop(['SKU', 'sales'], axis=1), train['sales'])\n",
    "\n",
    "# Group test data by SKU\n",
    "grouped = test.groupby('SKU')\n",
    "\n",
    "# Perform inference for each SKU in test data\n",
    "for sku, group_data in grouped:\n",
    "    print(f\"Performing inference for SKU: {sku}\")\n",
    "    \n",
    "    # Select one row from group data (one set of feature values for this SKU)\n",
    "    feature_values = group_data.iloc[0]\n",
    "    \n",
    "    # Set the base price from data\n",
    "    base_price = feature_values['price']\n",
    "    \n",
    "    # Define the price points\n",
    "    price_points = [base_price, \n",
    "                    base_price * 0.9,   # base_price - 10%\n",
    "                    base_price * 0.85,  # base_price - 15%\n",
    "                    base_price * 1.1,   # base_price + 10%\n",
    "                    base_price * 1.15]  # base_price + 15%\n",
    "    \n",
    "    predicted_sales_xgboost = []\n",
    "    \n",
    "    # For each price point, use the trained model to predict sales\n",
    "    for price in price_points:\n",
    "        # Change the price while keeping other features constant\n",
    "        test_features = feature_values.copy()\n",
    "        test_features['price'] = price\n",
    "        \n",
    "        # Remove the SKU field to match the input shape expected by the model\n",
    "        test_features = test_features.drop(['SKU', 'sales'])\n",
    "\n",
    "        # Predict sales using the XGBoost model\n",
    "        predicted_sales_xgboost.append(xgboost_model.predict(test_features.values.reshape(1, -1))[0])\n",
    "    \n",
    "    # Print the predicted sales at each price point\n",
    "    for price, xgboost_sales in zip(price_points, predicted_sales_xgboost):\n",
    "        print(f\"Price: {price}, XGBoost Predicted Sales: {xgboost_sales}\")\n",
    "\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "relu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
